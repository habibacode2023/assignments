{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# Make a decision on which URL you want to crawl \n",
    "cnn_url = \"https://bina.az/baki/alqi-satqi/menziller/yeni-tikili/\"\n",
    "html = requests.get(cnn_url)\n",
    "BeautifulSoup = soup(html.content, 'lxml')\n",
    "\n",
    "# Create empty lists to store the data\n",
    "prices = []\n",
    "descriptions = []\n",
    "locations = []\n",
    "\n",
    "# Make a decision on which URL you want to crawl \n",
    "cnn_url = \"https://bina.az/baki/alqi-satqi/menziller/yeni-tikili/\"\n",
    "html = requests.get(cnn_url)\n",
    "BeautifulSoup = soup(html.content, 'lxml')\n",
    "\n",
    "# Create empty lists to store the data\n",
    "prices = []\n",
    "descriptions = []\n",
    "locations = []\n",
    "for page in BeautifulSoup.findAll('span'):\n",
    "# Find all Headlines with h2 in HTML\n",
    "    for link in BeautifulSoup.findAll('div', attrs={'class':'card_params'}):\n",
    "        # Extract the data from the link and split it into separate parts\n",
    "        data=link.text.split('\\n')\n",
    "        price=link.text.split('AZN')\n",
    "        otaq=link.text.split('otaq')\n",
    "        #data = link.text.split()\n",
    "        print(data)  # Add this line to inspect the data\n",
    "\n",
    "        # Check if the data has the expected number of elements\n",
    "        if len(data) < 3:\n",
    "            continue  # Skip this iteration if the data is incomplete\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Price (AZN), Area (m²), Rooms, Floor]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# Make a decision on which URL you want to crawl\n",
    "cnn_url = \"https://bina.az/baki/alqi-satqi/menziller/yeni-tikili/\"\n",
    "html = requests.get(cnn_url)\n",
    "BeautifulSoup = soup(html.content, 'lxml')\n",
    "\n",
    "# Create empty lists to store the data\n",
    "prices = []\n",
    "areas = []\n",
    "rooms = []\n",
    "floors = []\n",
    "\n",
    "for link in BeautifulSoup.findAll('div', attrs={'class': 'card_params'}):\n",
    "    # Extract the data from the link and split it into separate parts\n",
    "    data = link.text.split('\\n')\n",
    "    \n",
    "    # Check if the data has the expected number of elements\n",
    "    if len(data) < 2:\n",
    "        continue\n",
    "\n",
    "    # Extract price (in AZN)\n",
    "    price_match = re.search(r'([\\d\\s,]+)AZN', data[0])\n",
    "    if price_match:\n",
    "        price = price_match.group(1).replace(',', '').strip()\n",
    "        prices.append(price)\n",
    "\n",
    "    # Extract area (in m²)\n",
    "    area_match = re.search(r'(\\d+\\.\\d+)\\s*m²', data[0])\n",
    "    if area_match:\n",
    "        area = area_match.group(1).strip()\n",
    "        areas.append(area)\n",
    "\n",
    "    # Extract the number of rooms\n",
    "    room_match = re.search(r'(\\d+)\\s*otaqlı', data[0])\n",
    "    if room_match:\n",
    "        room = room_match.group(1).strip()\n",
    "        rooms.append(room)\n",
    "\n",
    "    # Extract the floor information\n",
    "    floor_match = re.search(r'(\\d+)/(\\d+)\\s*mərtəbə', data[0])\n",
    "    if floor_match:\n",
    "        floor = floor_match.group(1) + '/' + floor_match.group(2)\n",
    "        floors.append(floor)\n",
    "\n",
    "# Create a DataFrame to store the extracted data\n",
    "data_df = pd.DataFrame({\n",
    "    'Price (AZN)': prices,\n",
    "    'Area (m²)': areas,\n",
    "    'Rooms': rooms,\n",
    "    'Floor': floors\n",
    "})\n",
    "\n",
    "# Print the DataFrame\n",
    "print(data_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "899e484c10671d1b5126d386f9569d04d1822dd8702e1f42f071736dee62f31c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
